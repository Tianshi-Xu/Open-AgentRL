- algorithm.adv_estimator=grpo
- algorithm.use_kl_in_reward=False
- algorithm.kl_ctrl.kl_coef=0.0
- data.train_files=['/data_storage/yzc/dataset/MegaScience/MegaScience/data/MegaScienceBench.parquet']
- data.val_files=['/data_storage/yzc/dataset/livecodebench/code_generation_lite/lcb_v6_2502_2505.parquet']
- data.return_raw_chat=True
- data.train_batch_size=64
- data.max_prompt_length=4096
- data.max_response_length=20480
- data.prompt_key=prompt
- data.filter_overlong_prompts=True
- data.truncation=error
- data.custom_cls.path=recipe/retool/retool.py
- data.custom_cls.name=CustomRLHFDataset
- custom_reward_function.path=recipe/retool/retool.py
- custom_reward_function.name=compute_score
- actor_rollout_ref.model.path=/data_storage/yzc/models/checkpoint/dapo_qwen3_4b_30k/global_step_300/huggingface
- actor_rollout_ref.model.use_remove_padding=True
- actor_rollout_ref.model.enable_gradient_checkpointing=True
- actor_rollout_ref.actor.use_kl_loss=False
- actor_rollout_ref.actor.kl_loss_coef=0.0
- actor_rollout_ref.actor.clip_ratio_low=0.2
- actor_rollout_ref.actor.clip_ratio_high=0.28
- actor_rollout_ref.actor.grad_clip=1.0
- actor_rollout_ref.actor.clip_ratio_c=10.0
- actor_rollout_ref.actor.loss_agg_mode=token-mean
- actor_rollout_ref.actor.optim.lr=1e-6
- actor_rollout_ref.actor.use_dynamic_bsz=True
- actor_rollout_ref.actor.ppo_mini_batch_size=16
- actor_rollout_ref.actor.ppo_max_token_len_per_gpu=24576
- actor_rollout_ref.actor.ulysses_sequence_parallel_size=4
- actor_rollout_ref.actor.fsdp_config.param_offload=True
- actor_rollout_ref.actor.fsdp_config.optimizer_offload=True
- actor_rollout_ref.ref.log_prob_max_token_len_per_gpu=98304
- actor_rollout_ref.rollout.name=vllm
- actor_rollout_ref.rollout.mode=async
- actor_rollout_ref.rollout.tensor_model_parallel_size=4
- actor_rollout_ref.rollout.multi_turn.enable=True
- actor_rollout_ref.rollout.multi_turn.max_user_turns=16
- actor_rollout_ref.rollout.multi_turn.max_assistant_turns=16
- actor_rollout_ref.rollout.multi_turn.tool_config_path=recipe/retool/sandbox_fusion_tool_config.yaml
- actor_rollout_ref.rollout.multi_turn.format=hermes
- actor_rollout_ref.rollout.gpu_memory_utilization=0.75
- actor_rollout_ref.rollout.n=16
- actor_rollout_ref.rollout.val_kwargs.top_p=0.6
- actor_rollout_ref.rollout.val_kwargs.temperature=1.0
- actor_rollout_ref.rollout.val_kwargs.n=5
- reward_model.reward_manager=dapo
- +reward_model.reward_kwargs.overlong_buffer_cfg.enable=True
- +reward_model.reward_kwargs.overlong_buffer_cfg.len=4096
- +reward_model.reward_kwargs.overlong_buffer_cfg.penalty_factor=1.0
- +reward_model.reward_kwargs.overlong_buffer_cfg.log=false
- +reward_model.reward_kwargs.max_resp_len=20480
- trainer.logger=[console,wandb]
- trainer.project_name=Evaluation
- trainer.experiment_name=dapo_qwen3_4b_300_lcbv6
- trainer.n_gpus_per_node=8
- trainer.val_before_train=True
- trainer.validation_data_dir=/data_storage/yzc/models/verl_rollouts/dapo_qwen3_4b_300_lcbv6/validation
- trainer.log_val_generations=20
- trainer.nnodes=1
- trainer.save_freq=30
- trainer.default_local_dir=/data_storage/yzc/models/verl_rollouts/dapo_qwen3_4b_300_lcbv6
- trainer.test_freq=10
- trainer.total_epochs=3
